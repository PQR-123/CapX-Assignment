{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d136b6af-5a07-4f39-9530-da7cb7a41dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from telethon import TelegramClient, sync\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b52c7bd-ddea-4012-ba81-b9a0792a4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telegram API credentials\n",
    "api_id = '29076802'  \n",
    "api_hash = 'bd9f1adca4a2363b3b677767c1ab8c72'  \n",
    "phone = '+917447342444'\n",
    "channel_username = 'https://t.me/freshershunt24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80eb65cf-5d06-4c03-b1e0-1e3abf225c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the process...\n",
      "Starting the Telegram scraper...\n",
      "Connecting to channel: https://t.me/freshershunt24\n",
      "Scraped 97 messages.\n",
      "Processing scraped messages...\n",
      "Starting preprocessing and sentiment analysis...\n",
      "Processed 97 messages.\n",
      "Building the machine learning model...\n",
      "Training the prediction model...\n",
      "Model Evaluation:\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00         3\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Apply nest_asyncio to allow running nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Telegram API credentials\n",
    "api_id = '29076802'  \n",
    "api_hash = 'bd9f1adca4a2363b3b677767c1ab8c72'  \n",
    "phone = '+917447342444'\n",
    "channel_username = 'https://t.me/freshershunt24'  \n",
    "\n",
    "# Create the TelegramClient instance\n",
    "client = TelegramClient('session_name', api_id, api_hash)\n",
    "\n",
    "async def scrape_telegram_data(client, channel_username, limit=100):\n",
    "    \"\"\"Scrapes messages from a Telegram channel.\"\"\"\n",
    "    print(f\"Connecting to channel: {channel_username}\")\n",
    "    await client.connect()  # Ensure the client is connected\n",
    "\n",
    "    history = await client(GetHistoryRequest(\n",
    "        peer=channel_username,\n",
    "        offset_id=0,\n",
    "        offset_date=None,\n",
    "        add_offset=0,\n",
    "        limit=limit,\n",
    "        max_id=0,\n",
    "        min_id=0,\n",
    "        hash=0\n",
    "    ))\n",
    "\n",
    "    messages = []\n",
    "    for message in history.messages:\n",
    "        if message.message:\n",
    "            messages.append(message.message)\n",
    "    print(f\"Scraped {len(messages)} messages.\")\n",
    "    return messages\n",
    "\n",
    "def preprocess_and_analyze(messages):\n",
    "    \"\"\"Preprocesses messages and performs sentiment analysis.\"\"\"\n",
    "    print(\"Starting preprocessing and sentiment analysis...\")\n",
    "    data = pd.DataFrame(messages, columns=['Message'])\n",
    "    data['Sentiment'] = data['Message'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    data['Label'] = data['Sentiment'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)\n",
    "    print(f\"Processed {len(data)} messages.\")\n",
    "    return data\n",
    "\n",
    "def build_model(data):\n",
    "    \"\"\"Builds and evaluates a machine learning model.\"\"\"\n",
    "    print(\"Training the prediction model...\")\n",
    "    X = data['Sentiment'].values.reshape(-1, 1)\n",
    "    y = data['Label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Model Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "async def async_main():\n",
    "    \"\"\"Main asynchronous function.\"\"\"\n",
    "    print(\"Starting the Telegram scraper...\")\n",
    "    async with client:  # Use 'async with' to manage the client connection\n",
    "        messages = await scrape_telegram_data(client, channel_username)\n",
    "        if not messages:\n",
    "            print(\"No messages scraped. Check channel username or permissions.\")\n",
    "            return\n",
    "\n",
    "        print(\"Processing scraped messages...\")\n",
    "        data = preprocess_and_analyze(messages)\n",
    "\n",
    "        print(\"Building the machine learning model...\")\n",
    "        build_model(data)\n",
    "        print(\"Process completed successfully.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point of the program.\"\"\"\n",
    "    print(\"Starting the process...\")\n",
    "    asyncio.run(async_main())  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecca147-0ac5-45ed-8755-46d75c9e9ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to channel...\n",
      "Scraped 97 messages.\n",
      "Starting preprocessing...\n",
      "Training the prediction model...\n",
      "Model Evaluation:\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00         5\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Model saved successfully as 'sentiment_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Telegram API credentials\n",
    "api_id = '29076802'  \n",
    "api_hash = 'bd9f1adca4a2363b3b677767c1ab8c72'  \n",
    "phone = '+917447342444'\n",
    "channel_username = 'https://t.me/freshershunt24'  # Remove https://t.me/\n",
    "\n",
    "# Create the client\n",
    "client = TelegramClient('session_name', api_id, api_hash)\n",
    "\n",
    "async def scrape_telegram_data(client, channel_username, limit=300):\n",
    "    try:\n",
    "        print(\"Connecting to channel...\")\n",
    "        await client.connect()\n",
    "        \n",
    "        if not await client.is_user_authorized():\n",
    "            print(\"User not authorized. Please check credentials.\")\n",
    "            return []\n",
    "\n",
    "        history = await client(GetHistoryRequest(\n",
    "            peer=channel_username,\n",
    "            offset_id=0,\n",
    "            offset_date=None,\n",
    "            add_offset=0,\n",
    "            limit=limit,\n",
    "            max_id=0,\n",
    "            min_id=0,\n",
    "            hash=0\n",
    "        ))\n",
    "\n",
    "        messages = []\n",
    "        for message in history.messages:\n",
    "            if message.message:\n",
    "                messages.append(message.message)\n",
    "        print(f\"Scraped {len(messages)} messages.\")\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def preprocess_and_analyze(messages):\n",
    "    print(\"Starting preprocessing...\")\n",
    "    data = pd.DataFrame(messages, columns=['Message'])\n",
    "    data['Sentiment'] = data['Message'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "    data['Label'] = data['Sentiment'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)\n",
    "    return data\n",
    "\n",
    "async def main():\n",
    "    async with client:\n",
    "        messages = await scrape_telegram_data(client, channel_username)\n",
    "        if messages:\n",
    "            data = preprocess_and_analyze(messages)\n",
    "            model = build_model(data)\n",
    "        else:\n",
    "            print(\"No messages to process\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db14dfd-404d-4761-a995-792c4e950a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Message: 'Great job opportunities for freshers!' -> Sentiment Label: Positive\n",
      "Message: 'This is a scam, do not trust!' -> Sentiment Label: Neutral\n",
      "Message: 'Neutral information about company policies.' -> Sentiment Label: Neutral\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import joblib\n",
    "import numpy as np  # Added for array operations\n",
    "\n",
    "def predict_sentiment(model, new_messages):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of new messages using the trained model.\n",
    "    Args:\n",
    "        model: Trained machine learning model.\n",
    "        new_messages: List of messages to analyze.\n",
    "    Returns:\n",
    "        List of predicted sentiment labels.\n",
    "    \"\"\"\n",
    "    if not isinstance(new_messages, list):\n",
    "        new_messages = [new_messages]  # Convert single message to list\n",
    "    \n",
    "    if not new_messages:\n",
    "        return []  # Return empty list if there are no messages;\"Local Settings\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate sentiment polarity for each message\n",
    "    try:\n",
    "        sentiments = np.array([TextBlob(str(msg)).sentiment.polarity for msg in new_messages])\n",
    "        # Reshape for sklearn compatibility\n",
    "        sentiments = sentiments.reshape(-1, 1)\n",
    "        \n",
    "        # Predict labels using the model\n",
    "        predictions = model.predict(sentiments)\n",
    "        return predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load the trained model\n",
    "        model = joblib.load(\"sentiment_model.pkl\")  # Fixed file extension\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        # New messages to analyze\n",
    "        new_messages = [\n",
    "            \"Great job opportunities for freshers!\",\n",
    "            \"This is a scam, do not trust!\",\n",
    "            \"Neutral information about company policies.\"\n",
    "        ]\n",
    "\n",
    "        # Predict sentiment for the new messages\n",
    "        predicted_labels = predict_sentiment(model, new_messages)\n",
    "\n",
    "        # Display predictions\n",
    "        if len(predicted_labels) > 0:\n",
    "            for msg, label in zip(new_messages, predicted_labels):\n",
    "                label_text = \"Positive\" if label == 1 else \"Negative\" if label == -1 else \"Neutral\"\n",
    "                print(f\"Message: '{msg}' -> Sentiment Label: {label_text}\")\n",
    "        else:\n",
    "            print(\"No predictions were generated.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Model file 'sentiment_model.pkl' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1506ac-1b13-4686-af3a-700777eefa45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
